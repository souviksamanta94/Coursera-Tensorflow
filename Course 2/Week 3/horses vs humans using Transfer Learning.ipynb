{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11512
    },
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "outputId": "b745da70-468f-4cb4-ee5b-f45124a2d2f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-20 08:03:50--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 2404:6800:4003:c04::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "\r",
      "          /tmp/ince   0%[                    ]       0  --.-KB/s               \r",
      "         /tmp/incep   4%[                    ]   4.01M  19.0MB/s               \r",
      "        /tmp/incept  38%[======>             ]  32.01M  70.4MB/s               \r",
      "       /tmp/incepti  76%[==============>     ]  64.01M  89.5MB/s               \r",
      "/tmp/inception_v3_w 100%[===================>]  83.84M  99.7MB/s    in 0.8s    \n",
      "\n",
      "2019-05-20 08:03:51 (99.7 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_94 (Batc (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_v1_94[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_95 (Batc (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_v1_95[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_96 (Batc (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_v1_96[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_97 (Batc (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_v1_97[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_98 (Batc (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_v1_98[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_102 (Bat (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_102[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_100 (Bat (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_103 (Bat (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_100[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_103[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_99 (Batc (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_101 (Bat (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_104 (Bat (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_105 (Bat (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_99[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_101[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_104[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_v1_105[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_109 (Bat (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_109[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_107 (Bat (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_110 (Bat (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_107[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_110[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_106 (Bat (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_108 (Bat (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_111 (Bat (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_112 (Bat (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_106[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_108[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_111[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_112[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_116 (Bat (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_116[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_114 (Bat (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_117 (Bat (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_114[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_117[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_113 (Bat (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_115 (Bat (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_118 (Bat (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_119 (Bat (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_113[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_115[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_118[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_119[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_121 (Bat (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_121[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_122 (Bat (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_122[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_120 (Bat (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_123 (Bat (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_v1_120[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_v1_123[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_128 (Bat (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_128[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_129 (Bat (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_129[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_125 (Bat (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_130 (Bat (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_125[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_130[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_126 (Bat (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_131 (Bat (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_126[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_131[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_124 (Bat (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_127 (Bat (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_132 (Bat (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_133 (Bat (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_124[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_127[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_132[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_133[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_138 (Bat (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_138[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_139 (Bat (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_139[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_135 (Bat (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_140 (Bat (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_135[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_140[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_136 (Bat (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_141 (Bat (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_136[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_141[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_134 (Bat (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_137 (Bat (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_142 (Bat (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_143 (Bat (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_134[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_137[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_142[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_143[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_148 (Bat (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_148[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_149 (Bat (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_149[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_145 (Bat (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_150 (Bat (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_145[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_150[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_146 (Bat (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_151 (Bat (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_146[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_151[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_144 (Bat (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_147 (Bat (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_152 (Bat (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_153 (Bat (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_144[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_152[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_153[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_158 (Bat (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_158[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_159 (Bat (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_159[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_155 (Bat (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_160 (Bat (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_155[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_160[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_156 (Bat (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_161 (Bat (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_156[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_161[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_154 (Bat (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_157 (Bat (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_162 (Bat (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_163 (Bat (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_154[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_157[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_162[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_163[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_166 (Bat (None, 7, 7, 192)    576         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_166[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 192)    258048      activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_167 (Bat (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_167[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_164 (Bat (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_168 (Bat (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_164[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_168[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 3, 3, 320)    552960      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 3, 3, 192)    331776      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_165 (Bat (None, 3, 3, 320)    960         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_169 (Bat (None, 3, 3, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_165[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_169[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_165[0][0]             \n",
      "                                                                 activation_169[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_174 (Bat (None, 3, 3, 448)    1344        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 448)    0           batch_normalization_v1_174[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 384)    1548288     activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_171 (Bat (None, 3, 3, 384)    1152        conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_175 (Bat (None, 3, 3, 384)    1152        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_171[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_175[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_172 (Bat (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_173 (Bat (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_176 (Bat (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_177 (Bat (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_170 (Bat (None, 3, 3, 320)    960         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_172[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_173[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_176[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_177[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_178 (Bat (None, 3, 3, 192)    576         conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_170[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_172[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 3, 768)    0           activation_176[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_178[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_170[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_183 (Bat (None, 3, 3, 448)    1344        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 448)    0           batch_normalization_v1_183[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 384)    1548288     activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_180 (Bat (None, 3, 3, 384)    1152        conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_184 (Bat (None, 3, 3, 384)    1152        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_180[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_184[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_181 (Bat (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_182 (Bat (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_185 (Bat (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_186 (Bat (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_179 (Bat (None, 3, 3, 320)    960         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_181[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_182[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_185[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_v1_186[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_187 (Bat (None, 3, 3, 192)    576         conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_179[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_181[0][0]             \n",
      "                                                                 activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_187[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_179[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_187[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Download the inception v3 weights\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape=(150,150,3), include_top=False,weights=None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  # Your Code Here\n",
    "  layer.trainable=False\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CFsUlwdfs_wg",
    "outputId": "41b3a88f-8e05-4a53-a3ac-273b4f8199a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('last layer output shape: ', (None, 7, 7, 768))\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.999 and logs.get('val_acc')>0.99):\n",
    "      print(\"\\nReached 99.9% accuracy and 99% validation accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8520
    },
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "outputId": "75dbf3aa-f9f6-4977-fdec-5a37a6c38d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_94 (Batc (None, 74, 74, 32)   96          conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 74, 74, 32)   0           batch_normalization_v1_94[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 72, 72, 32)   9216        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_95 (Batc (None, 72, 72, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 72, 72, 32)   0           batch_normalization_v1_95[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 64)   18432       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_96 (Batc (None, 72, 72, 64)   192         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 64)   0           batch_normalization_v1_96[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_97 (Batc (None, 35, 35, 80)   240         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 35, 35, 80)   0           batch_normalization_v1_97[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 33, 33, 192)  138240      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_98 (Batc (None, 33, 33, 192)  576         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 33, 33, 192)  0           batch_normalization_v1_98[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_102 (Bat (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_102[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 96)   55296       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_100 (Bat (None, 16, 16, 48)   144         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_103 (Bat (None, 16, 16, 96)   288         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_100[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_103[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 64)   76800       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   82944       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_99 (Batc (None, 16, 16, 64)   192         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_101 (Bat (None, 16, 16, 64)   192         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_104 (Bat (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_105 (Bat (None, 16, 16, 32)   96          conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_99[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_101[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_104[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 32)   0           batch_normalization_v1_105[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 activation_104[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_109 (Bat (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_109[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 96)   55296       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_107 (Bat (None, 16, 16, 48)   144         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_110 (Bat (None, 16, 16, 96)   288         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_107[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_110[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 64)   76800       activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   82944       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_106 (Bat (None, 16, 16, 64)   192         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_108 (Bat (None, 16, 16, 64)   192         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_111 (Bat (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_112 (Bat (None, 16, 16, 64)   192         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_106[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_108[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_111[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_112[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_106[0][0]             \n",
      "                                                                 activation_108[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_116 (Bat (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_116[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 96)   55296       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_114 (Bat (None, 16, 16, 48)   144         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_117 (Bat (None, 16, 16, 96)   288         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 48)   0           batch_normalization_v1_114[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_117[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 64)   76800       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   82944       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_113 (Bat (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_115 (Bat (None, 16, 16, 64)   192         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_118 (Bat (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_119 (Bat (None, 16, 16, 64)   192         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_113[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_115[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_118[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_119[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_113[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_118[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_121 (Bat (None, 16, 16, 64)   192         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 64)   0           batch_normalization_v1_121[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 96)   55296       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_122 (Bat (None, 16, 16, 96)   288         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 96)   0           batch_normalization_v1_122[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 96)     82944       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_120 (Bat (None, 7, 7, 384)    1152        conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_123 (Bat (None, 7, 7, 96)     288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 384)    0           batch_normalization_v1_120[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 7, 7, 96)     0           batch_normalization_v1_123[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_120[0][0]             \n",
      "                                                                 activation_123[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_128 (Bat (None, 7, 7, 128)    384         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_128[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    114688      activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_129 (Bat (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_129[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_125 (Bat (None, 7, 7, 128)    384         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_130 (Bat (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_125[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_130[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    114688      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_126 (Bat (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_131 (Bat (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_126[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_v1_131[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    172032      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 192)    172032      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_124 (Bat (None, 7, 7, 192)    576         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_127 (Bat (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_132 (Bat (None, 7, 7, 192)    576         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_133 (Bat (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_124[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_127[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_132[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_133[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_124[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 activation_132[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_138 (Bat (None, 7, 7, 160)    480         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_138[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    179200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_139 (Bat (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_139[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_135 (Bat (None, 7, 7, 160)    480         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_140 (Bat (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_135[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_140[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    179200      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_136 (Bat (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_141 (Bat (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_136[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_141[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 192)    215040      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 192)    215040      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_134 (Bat (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_137 (Bat (None, 7, 7, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_142 (Bat (None, 7, 7, 192)    576         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_143 (Bat (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_134[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_137[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_142[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_143[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_137[0][0]             \n",
      "                                                                 activation_142[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_148 (Bat (None, 7, 7, 160)    480         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_148[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    179200      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_149 (Bat (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_149[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_145 (Bat (None, 7, 7, 160)    480         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_150 (Bat (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_145[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_150[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    179200      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_146 (Bat (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_151 (Bat (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_146[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_v1_151[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 192)    215040      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 192)    215040      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_144 (Bat (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_147 (Bat (None, 7, 7, 192)    576         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_152 (Bat (None, 7, 7, 192)    576         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_153 (Bat (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_144[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_152[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_153[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_144[0][0]             \n",
      "                                                                 activation_147[0][0]             \n",
      "                                                                 activation_152[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_158 (Bat (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_158[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    258048      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_159 (Bat (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_159[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_155 (Bat (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_160 (Bat (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_155[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_160[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    258048      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_156 (Bat (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_161 (Bat (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_156[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_161[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_154 (Bat (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_157 (Bat (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_162 (Bat (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_163 (Bat (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_154[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_157[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_162[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_v1_163[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_154[0][0]             \n",
      "                                                                 activation_157[0][0]             \n",
      "                                                                 activation_162[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "HrnL_IQ8knWA",
    "outputId": "73706aed-614e-463b-f2e5-95a0fd7d8c0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-20 07:56:26--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.130.128, 2404:6800:4003:c04::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.130.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149574867 (143M) [application/zip]\n",
      "Saving to: ‘/tmp/horse-or-human.zip’\n",
      "\n",
      "/tmp/horse-or-human 100%[===================>] 142.65M  95.4MB/s    in 1.5s    \n",
      "\n",
      "2019-05-20 07:56:28 (95.4 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
      "\n",
      "--2019-05-20 07:56:31--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.130.128, 2404:6800:4003:c01::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.130.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11480187 (11M) [application/zip]\n",
      "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
      "\n",
      "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-05-20 07:56:31 (75.0 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the Horse or Human dataset\n",
    "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
    "\n",
    "# Get the Horse or Human Validation dataset\n",
    "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
    "  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '//tmp/horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = '//tmp/validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "y9okX7_ovskI",
    "outputId": "5377f14b-8f46-4c8e-dee2-8b4891c6596f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "train_horses_dir = '/tmp/training/horses'\n",
    "train_humans_dir = '/tmp/training/humans'\n",
    "validation_horses_dir = '/tmp/validation/horses'\n",
    "validation_humans_dir = '/tmp/validation/humans'\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "O4s8HckqGlnb",
    "outputId": "e03a1f2e-64d5-425f-d543-290fd3347555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                   target_size=(150,150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                   batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                   target_size=(150,150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5117
    },
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "outputId": "faabaa5b-0831-416b-e044-53c5ad83482f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.6551 - acc: 0.9453\n",
      " - 13s - loss: 0.0161 - acc: 0.9961 - val_loss: 0.6551 - val_acc: 0.9453\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.5332 - acc: 0.9531\n",
      " - 12s - loss: 0.0243 - acc: 0.9961 - val_loss: 0.5332 - val_acc: 0.9531\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.5458 - acc: 0.9570\n",
      " - 11s - loss: 0.0162 - acc: 0.9971 - val_loss: 0.5458 - val_acc: 0.9570\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2402 - acc: 0.9766\n",
      " - 11s - loss: 0.0117 - acc: 0.9990 - val_loss: 0.2402 - val_acc: 0.9766\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3382 - acc: 0.9609\n",
      " - 11s - loss: 0.0212 - acc: 0.9942 - val_loss: 0.3382 - val_acc: 0.9609\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.3250 - acc: 0.9609\n",
      " - 11s - loss: 0.0114 - acc: 0.9961 - val_loss: 0.3250 - val_acc: 0.9609\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.3282 - acc: 0.9609\n",
      " - 11s - loss: 0.0039 - acc: 0.9981 - val_loss: 0.3282 - val_acc: 0.9609\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.3499 - acc: 0.9609\n",
      " - 12s - loss: 0.0059 - acc: 0.9971 - val_loss: 0.3499 - val_acc: 0.9609\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.1890 - acc: 0.9727\n",
      " - 12s - loss: 0.0190 - acc: 0.9971 - val_loss: 0.1890 - val_acc: 0.9727\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 2s 127ms/step - loss: 0.1860 - acc: 0.9688\n",
      " - 12s - loss: 9.1221e-04 - acc: 1.0000 - val_loss: 0.1860 - val_acc: 0.9688\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.1919 - acc: 0.9688\n",
      " - 12s - loss: 0.0120 - acc: 0.9961 - val_loss: 0.1919 - val_acc: 0.9688\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3127 - acc: 0.9570\n",
      " - 11s - loss: 0.0241 - acc: 0.9951 - val_loss: 0.3127 - val_acc: 0.9570\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.1860 - acc: 0.9805\n",
      " - 11s - loss: 0.0018 - acc: 0.9990 - val_loss: 0.1860 - val_acc: 0.9805\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.3040 - acc: 0.9570\n",
      " - 11s - loss: 0.0333 - acc: 0.9922 - val_loss: 0.3040 - val_acc: 0.9570\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 2s 124ms/step - loss: 0.2497 - acc: 0.9648\n",
      " - 13s - loss: 0.0054 - acc: 0.9981 - val_loss: 0.2497 - val_acc: 0.9648\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.1283 - acc: 0.9883\n",
      " - 12s - loss: 0.0141 - acc: 0.9961 - val_loss: 0.1283 - val_acc: 0.9883\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.1243 - acc: 0.9922\n",
      " - 11s - loss: 0.0108 - acc: 0.9942 - val_loss: 0.1243 - val_acc: 0.9922\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3540 - acc: 0.9570\n",
      " - 11s - loss: 0.0128 - acc: 0.9961 - val_loss: 0.3540 - val_acc: 0.9570\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.1905 - acc: 0.9727\n",
      " - 11s - loss: 0.0032 - acc: 0.9981 - val_loss: 0.1905 - val_acc: 0.9727\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3433 - acc: 0.9570\n",
      " - 11s - loss: 1.0120e-04 - acc: 1.0000 - val_loss: 0.3433 - val_acc: 0.9570\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.1699 - acc: 0.9844\n",
      " - 11s - loss: 0.0091 - acc: 0.9951 - val_loss: 0.1699 - val_acc: 0.9844\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.4723 - acc: 0.9531\n",
      " - 13s - loss: 0.0118 - acc: 0.9971 - val_loss: 0.4723 - val_acc: 0.9531\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.3098 - acc: 0.9609\n",
      " - 11s - loss: 0.0253 - acc: 0.9961 - val_loss: 0.3098 - val_acc: 0.9609\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3560 - acc: 0.9609\n",
      " - 11s - loss: 0.0099 - acc: 0.9971 - val_loss: 0.3560 - val_acc: 0.9609\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2587 - acc: 0.9648\n",
      " - 11s - loss: 0.0085 - acc: 0.9971 - val_loss: 0.2587 - val_acc: 0.9648\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6176 - acc: 0.9453\n",
      " - 11s - loss: 0.0395 - acc: 0.9932 - val_loss: 0.6176 - val_acc: 0.9453\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4956 - acc: 0.9531\n",
      " - 11s - loss: 1.3913e-04 - acc: 1.0000 - val_loss: 0.4956 - val_acc: 0.9531\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.6471 - acc: 0.9492\n",
      " - 11s - loss: 0.0134 - acc: 0.9961 - val_loss: 0.6471 - val_acc: 0.9492\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.7661 - acc: 0.9414\n",
      " - 13s - loss: 0.0014 - acc: 0.9990 - val_loss: 0.7661 - val_acc: 0.9414\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.6772 - acc: 0.9492\n",
      " - 11s - loss: 0.0189 - acc: 0.9971 - val_loss: 0.6772 - val_acc: 0.9492\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.5030 - acc: 0.9492\n",
      " - 11s - loss: 0.0302 - acc: 0.9951 - val_loss: 0.5030 - val_acc: 0.9492\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6355 - acc: 0.9453\n",
      " - 12s - loss: 0.0077 - acc: 0.9961 - val_loss: 0.6355 - val_acc: 0.9453\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.7090 - acc: 0.9453\n",
      " - 11s - loss: 5.4669e-04 - acc: 1.0000 - val_loss: 0.7090 - val_acc: 0.9453\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.6998 - acc: 0.9453\n",
      " - 11s - loss: 0.0124 - acc: 0.9981 - val_loss: 0.6998 - val_acc: 0.9453\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.7276 - acc: 0.9453\n",
      " - 11s - loss: 0.0179 - acc: 0.9961 - val_loss: 0.7276 - val_acc: 0.9453\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6448 - acc: 0.9492\n",
      " - 13s - loss: 0.0127 - acc: 0.9951 - val_loss: 0.6448 - val_acc: 0.9492\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.2926 - acc: 0.9609\n",
      " - 13s - loss: 0.0064 - acc: 0.9981 - val_loss: 0.2926 - val_acc: 0.9609\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.6362 - acc: 0.9492\n",
      " - 11s - loss: 2.5976e-04 - acc: 1.0000 - val_loss: 0.6362 - val_acc: 0.9492\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6468 - acc: 0.9492\n",
      " - 11s - loss: 0.0149 - acc: 0.9981 - val_loss: 0.6468 - val_acc: 0.9492\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.1796 - acc: 0.9844\n",
      " - 11s - loss: 0.0129 - acc: 0.9961 - val_loss: 0.1796 - val_acc: 0.9844\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.1986 - acc: 0.9805\n",
      " - 12s - loss: 0.0114 - acc: 0.9981 - val_loss: 0.1986 - val_acc: 0.9805\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 2s 123ms/step - loss: 0.4078 - acc: 0.9609\n",
      " - 12s - loss: 0.0285 - acc: 0.9932 - val_loss: 0.4078 - val_acc: 0.9609\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.3369 - acc: 0.9609\n",
      " - 13s - loss: 0.0229 - acc: 0.9961 - val_loss: 0.3369 - val_acc: 0.9609\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.3367 - acc: 0.9609\n",
      " - 11s - loss: 0.0108 - acc: 0.9971 - val_loss: 0.3367 - val_acc: 0.9609\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3632 - acc: 0.9570\n",
      " - 11s - loss: 0.0210 - acc: 0.9951 - val_loss: 0.3632 - val_acc: 0.9570\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.3443 - acc: 0.9609\n",
      " - 12s - loss: 0.0020 - acc: 0.9990 - val_loss: 0.3443 - val_acc: 0.9609\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6053 - acc: 0.9531\n",
      " - 11s - loss: 0.0047 - acc: 0.9981 - val_loss: 0.6053 - val_acc: 0.9531\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.4810 - acc: 0.9531\n",
      " - 11s - loss: 0.0255 - acc: 0.9951 - val_loss: 0.4810 - val_acc: 0.9531\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.6192 - acc: 0.9492\n",
      " - 12s - loss: 0.0018 - acc: 0.9990 - val_loss: 0.6192 - val_acc: 0.9492\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4922 - acc: 0.9492\n",
      " - 12s - loss: 5.0818e-04 - acc: 1.0000 - val_loss: 0.4922 - val_acc: 0.9492\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.1239 - acc: 0.9922\n",
      " - 11s - loss: 0.0216 - acc: 0.9961 - val_loss: 0.1239 - val_acc: 0.9922\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.2765 - acc: 0.9648\n",
      " - 11s - loss: 5.7756e-04 - acc: 1.0000 - val_loss: 0.2765 - val_acc: 0.9648\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.3899 - acc: 0.9570\n",
      " - 11s - loss: 0.0092 - acc: 0.9981 - val_loss: 0.3899 - val_acc: 0.9570\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.5373 - acc: 0.9531\n",
      " - 11s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.5373 - val_acc: 0.9531\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4913 - acc: 0.9531\n",
      " - 11s - loss: 0.0136 - acc: 0.9971 - val_loss: 0.4913 - val_acc: 0.9531\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 2s 124ms/step - loss: 0.6827 - acc: 0.9492\n",
      " - 12s - loss: 0.0108 - acc: 0.9981 - val_loss: 0.6827 - val_acc: 0.9492\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.5042 - acc: 0.9531\n",
      " - 12s - loss: 8.8739e-05 - acc: 1.0000 - val_loss: 0.5042 - val_acc: 0.9531\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4145 - acc: 0.9570\n",
      " - 11s - loss: 0.0112 - acc: 0.9961 - val_loss: 0.4145 - val_acc: 0.9570\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.5426 - acc: 0.9531\n",
      " - 11s - loss: 4.7675e-04 - acc: 1.0000 - val_loss: 0.5426 - val_acc: 0.9531\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4641 - acc: 0.9609\n",
      " - 11s - loss: 0.0064 - acc: 0.9981 - val_loss: 0.4641 - val_acc: 0.9609\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.5045 - acc: 0.9570\n",
      " - 11s - loss: 5.3995e-04 - acc: 1.0000 - val_loss: 0.5045 - val_acc: 0.9570\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4208 - acc: 0.9570\n",
      " - 11s - loss: 0.0073 - acc: 0.9981 - val_loss: 0.4208 - val_acc: 0.9570\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 2s 127ms/step - loss: 0.3147 - acc: 0.9648\n",
      " - 12s - loss: 0.0268 - acc: 0.9951 - val_loss: 0.3147 - val_acc: 0.9648\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2890 - acc: 0.9648\n",
      " - 13s - loss: 0.0133 - acc: 0.9971 - val_loss: 0.2890 - val_acc: 0.9648\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.4939 - acc: 0.9492\n",
      " - 11s - loss: 0.0079 - acc: 0.9990 - val_loss: 0.4939 - val_acc: 0.9492\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.5498 - acc: 0.9492\n",
      " - 11s - loss: 0.0024 - acc: 0.9990 - val_loss: 0.5498 - val_acc: 0.9492\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.1487 - acc: 0.9805\n",
      " - 12s - loss: 0.0120 - acc: 0.9971 - val_loss: 0.1487 - val_acc: 0.9805\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.2135 - acc: 0.9727\n",
      " - 12s - loss: 0.0128 - acc: 0.9971 - val_loss: 0.2135 - val_acc: 0.9727\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.2056 - acc: 0.9727\n",
      " - 11s - loss: 0.0020 - acc: 0.9990 - val_loss: 0.2056 - val_acc: 0.9727\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.1661 - acc: 0.9805\n",
      " - 12s - loss: 0.0146 - acc: 0.9961 - val_loss: 0.1661 - val_acc: 0.9805\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2527 - acc: 0.9688\n",
      " - 12s - loss: 0.0085 - acc: 0.9990 - val_loss: 0.2527 - val_acc: 0.9688\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.4619 - acc: 0.9492\n",
      " - 11s - loss: 0.0320 - acc: 0.9971 - val_loss: 0.4619 - val_acc: 0.9492\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3582 - acc: 0.9531\n",
      " - 11s - loss: 0.0122 - acc: 0.9971 - val_loss: 0.3582 - val_acc: 0.9531\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.1686 - acc: 0.9805\n",
      " - 11s - loss: 0.0013 - acc: 0.9990 - val_loss: 0.1686 - val_acc: 0.9805\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2522 - acc: 0.9688\n",
      " - 11s - loss: 0.0129 - acc: 0.9951 - val_loss: 0.2522 - val_acc: 0.9688\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.3493 - acc: 0.9531\n",
      " - 11s - loss: 0.0102 - acc: 0.9981 - val_loss: 0.3493 - val_acc: 0.9531\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.4748 - acc: 0.9492\n",
      " - 13s - loss: 9.1062e-04 - acc: 1.0000 - val_loss: 0.4748 - val_acc: 0.9492\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4475 - acc: 0.9570\n",
      " - 12s - loss: 0.0016 - acc: 0.9990 - val_loss: 0.4475 - val_acc: 0.9570\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.1382 - acc: 0.9883\n",
      " - 11s - loss: 0.0018 - acc: 0.9990 - val_loss: 0.1382 - val_acc: 0.9883\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.7729 - acc: 0.9414\n",
      " - 11s - loss: 0.0178 - acc: 0.9922 - val_loss: 0.7729 - val_acc: 0.9414\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.7152 - acc: 0.9414\n",
      " - 12s - loss: 6.8119e-05 - acc: 1.0000 - val_loss: 0.7152 - val_acc: 0.9414\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2371 - acc: 0.9727\n",
      " - 11s - loss: 0.0068 - acc: 0.9981 - val_loss: 0.2371 - val_acc: 0.9727\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.7115 - acc: 0.9414\n",
      " - 11s - loss: 0.0112 - acc: 0.9981 - val_loss: 0.7115 - val_acc: 0.9414\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.6228 - acc: 0.9492\n",
      " - 13s - loss: 1.5363e-04 - acc: 1.0000 - val_loss: 0.6228 - val_acc: 0.9492\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.5358 - acc: 0.9492\n",
      " - 12s - loss: 0.0025 - acc: 0.9981 - val_loss: 0.5358 - val_acc: 0.9492\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.6232 - acc: 0.9492\n",
      " - 11s - loss: 0.0014 - acc: 0.9990 - val_loss: 0.6232 - val_acc: 0.9492\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.7864 - acc: 0.9375\n",
      " - 11s - loss: 0.0040 - acc: 0.9981 - val_loss: 0.7864 - val_acc: 0.9375\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.7776 - acc: 0.9375\n",
      " - 11s - loss: 0.0326 - acc: 0.9971 - val_loss: 0.7776 - val_acc: 0.9375\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.2127 - acc: 0.9727\n",
      " - 11s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.2127 - val_acc: 0.9727\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 2s 127ms/step - loss: 0.2956 - acc: 0.9688\n",
      " - 13s - loss: 0.0078 - acc: 0.9990 - val_loss: 0.2956 - val_acc: 0.9688\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3919 - acc: 0.9570\n",
      " - 13s - loss: 0.0046 - acc: 0.9990 - val_loss: 0.3919 - val_acc: 0.9570\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.3234 - acc: 0.9648\n",
      " - 11s - loss: 0.0200 - acc: 0.9971 - val_loss: 0.3234 - val_acc: 0.9648\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 2s 125ms/step - loss: 0.5224 - acc: 0.9570\n",
      " - 12s - loss: 0.0200 - acc: 0.9971 - val_loss: 0.5224 - val_acc: 0.9570\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6166 - acc: 0.9531\n",
      " - 12s - loss: 0.0036 - acc: 0.9990 - val_loss: 0.6166 - val_acc: 0.9531\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.7936 - acc: 0.9414\n",
      " - 11s - loss: 0.0291 - acc: 0.9942 - val_loss: 0.7936 - val_acc: 0.9414\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.2880 - acc: 0.9648\n",
      " - 11s - loss: 0.0027 - acc: 0.9990 - val_loss: 0.2880 - val_acc: 0.9648\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.5897 - acc: 0.9531\n",
      " - 11s - loss: 0.0037 - acc: 0.9981 - val_loss: 0.5897 - val_acc: 0.9531\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2100 - acc: 0.9766\n",
      " - 13s - loss: 0.0219 - acc: 0.9981 - val_loss: 0.2100 - val_acc: 0.9766\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.5771 - acc: 0.9492\n",
      " - 11s - loss: 0.0125 - acc: 0.9981 - val_loss: 0.5771 - val_acc: 0.9492\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2590 - acc: 0.9727\n",
      " - 11s - loss: 0.0270 - acc: 0.9942 - val_loss: 0.2590 - val_acc: 0.9727\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 99.9% accuracy\n",
    "# (It should take less than 100 epochs)\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 100,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2,\n",
    "            callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL",
    "outputId": "d0da7571-e342-4a40-aba4-04df3f6bbf53"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Coursera-CNN using Tensorflow course-horses vs humans using Transfer Learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
